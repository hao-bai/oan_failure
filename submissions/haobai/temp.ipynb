{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "050ee7e0",
   "metadata": {},
   "source": [
    "# 数据集概览\n",
    "## Load datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d220bd",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train data\n",
      "Optical Dataset composed of\n",
      "46110 source samples\n",
      "50862 source background samples\n",
      "438 target labeled samples\n",
      "8202 target unlabeled samples\n",
      "29592 target background samples\n",
      " Optical Dataset labels composed of\n",
      "46110 labels of source samples\n",
      "438 labels of target samples\n",
      "\n",
      "Test data\n",
      "Optical Dataset composed of\n",
      "0 source samples\n",
      "0 source background samples\n",
      "17758 target labeled samples\n",
      "0 target unlabeled samples\n",
      "47275 target background samples\n",
      " Optical Dataset labels composed of\n",
      "0 labels of source samples\n",
      "17758 labels of target samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import rampwf as rw\n",
    "from contextlib import contextmanager\n",
    "@contextmanager\n",
    "def cd(newdir):\n",
    "    if isinstance(newdir, pathlib.Path):\n",
    "        newdir = str(newdir)\n",
    "    prevdir = os.getcwd()  # save current working path\n",
    "    os.chdir(os.path.expanduser(newdir))  # change directory\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        os.chdir(prevdir)  # revert to the origin workinng path\n",
    "with cd(\"~/Codes/HuaweiRAMP\"):\n",
    "    problem = rw.utils.assert_read_problem()\n",
    "    X_train, y_train = problem.get_train_data()\n",
    "    X_test, y_test = problem.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "405d870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(formatter={\"float\":lambda x: \"{:.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d90a5",
   "metadata": {},
   "source": [
    "## 训练集\n",
    "### City A (source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1fac2c",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "source labeled (City A weak & failure): (46110, 672, 10)\n|- labels: (46110,)\n |- weak=0: (41341,)\n |- failure=1: (4769,)\nsource background (City A good): (50862, 672, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"source labeled (City A weak & failure):\", X_train.source.shape)\n",
    "# print(np.where(np.isnan(X_train.source[0])))\n",
    "print(\"|- labels:\", y_train.source.shape)\n",
    "print(\" |- weak=0:\", y_train.source[y_train.source==0].shape)\n",
    "print(\" |- failure=1:\", y_train.source[y_train.source==1].shape)\n",
    "print(\"source background (City A good):\", X_train.source_bkg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c46269",
   "metadata": {},
   "source": [
    "### City B (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a352a534",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "target labeled (City B weak & failure): (438, 672, 10)\n|- labels: (438,)\n |- weak=0: (349,)\n |- failure=1: (89,)\ntarget background (City B good): (29592, 672, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"target labeled (City B weak & failure):\", X_train.target.shape)\n",
    "print(\"|- labels:\", y_train.target.shape)\n",
    "print(\" |- weak=0:\", y_train.target[y_train.target==0].shape)\n",
    "print(\" |- failure=1:\", y_train.target[y_train.target==1].shape)\n",
    "print(\"target background (City B good):\", X_train.target_bkg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918cf6d7",
   "metadata": {},
   "source": [
    "## 测试集\n",
    "### City B (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c25788d9",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "target labeled (City B weak & failure): (17758, 672, 10)\n|- labels: (17758,)\n |- weak=0: (15464,)\n |- failure=1: (2294,)\ntarget background (City B good): (47275, 672, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"target labeled (City B weak & failure):\", X_test.target.shape)\n",
    "print(\"|- labels:\", y_test.target.shape)\n",
    "print(\" |- weak=0:\", y_test.target[y_test.target==0].shape)\n",
    "print(\" |- failure=1:\", y_test.target[y_test.target==1].shape)\n",
    "print(\"target background (City B good):\", X_test.target_bkg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8626c2",
   "metadata": {},
   "source": [
    "# Residual Neural Network\n",
    "## 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76799a13",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(46110, 672, 10, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# 去除NaN\n",
    "from feature_extractor import FeatureExtractor\n",
    "from numpy import newaxis\n",
    "class FE(FeatureExtractor):\n",
    "    def transform(self, X):\n",
    "        np.nan_to_num(X, copy=False)\n",
    "        return X[:,:,:,newaxis]\n",
    "\n",
    "fe = FE()\n",
    "X_train.source = fe.transform(X_train.source)\n",
    "X_train.target = fe.transform(X_train.target)\n",
    "X_test.target = fe.transform(X_test.target)\n",
    "X_train.source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 将数据集转换为TensorFlow格式\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train.source, y_train.source)).batch(16)\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((X_train.target, y_train.target)).batch(16)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test.target, y_test.target))\n",
    "\n",
    "# 额外操作\n",
    "train_dataset = train_dataset.map( lambda x, y: (tf.image.random_flip_left_right(x), y) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0\n[0.000]\n"
     ]
    }
   ],
   "source": [
    "from numpy import zeros, newaxis\n",
    "a= zeros((4,3))\n",
    "print(a[0][0])\n",
    "b=a[:,:,newaxis]\n",
    "print(b[0][0])"
   ]
  },
  {
   "source": [
    "## 搭建网络模型\n",
    "参考资料\n",
    "\n",
    "1. [Introduction to ResNet in TensorFlow 2](https://adventuresinmachinelearning.com/introduction-resnet-tensorflow-2/)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_net_block(filters, conv_size, input_data):\n",
    "    ''' A residual block of 3 layers\n",
    "    '''\n",
    "    # 1st layer with batch normalization\n",
    "    x = layers.Conv2D(filters, conv_size, activation='relu', padding='same')(input_data)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # 2nd layer with batch normalization, but no activation function\n",
    "    x = layers.Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # 3rd layer is residual addition with an activation function\n",
    "    x = layers.Add()([x, input_data])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nInput_Layer (InputLayer)        [(None, 672, 10, 1)] 0                                            \n__________________________________________________________________________________________________\nLayer01 (Conv2D)                (None, 671, 9, 32)   160         Input_Layer[0][0]                \n__________________________________________________________________________________________________\nLayer02 (Conv2D)                (None, 670, 8, 64)   8256        Layer01[0][0]                    \n__________________________________________________________________________________________________\nLayer03 (MaxPooling2D)          (None, 335, 4, 64)   0           Layer02[0][0]                    \n__________________________________________________________________________________________________\nconv2d_60 (Conv2D)              (None, 335, 4, 64)   16448       Layer03[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_60 (BatchNo (None, 335, 4, 64)   256         conv2d_60[0][0]                  \n__________________________________________________________________________________________________\nconv2d_61 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_60[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_61 (BatchNo (None, 335, 4, 64)   256         conv2d_61[0][0]                  \n__________________________________________________________________________________________________\nadd_30 (Add)                    (None, 335, 4, 64)   0           batch_normalization_61[0][0]     \n                                                                 Layer03[0][0]                    \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 335, 4, 64)   0           add_30[0][0]                     \n__________________________________________________________________________________________________\nconv2d_62 (Conv2D)              (None, 335, 4, 64)   16448       activation_30[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_62 (BatchNo (None, 335, 4, 64)   256         conv2d_62[0][0]                  \n__________________________________________________________________________________________________\nconv2d_63 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_62[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_63 (BatchNo (None, 335, 4, 64)   256         conv2d_63[0][0]                  \n__________________________________________________________________________________________________\nadd_31 (Add)                    (None, 335, 4, 64)   0           batch_normalization_63[0][0]     \n                                                                 activation_30[0][0]              \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 335, 4, 64)   0           add_31[0][0]                     \n__________________________________________________________________________________________________\nconv2d_64 (Conv2D)              (None, 335, 4, 64)   16448       activation_31[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_64 (BatchNo (None, 335, 4, 64)   256         conv2d_64[0][0]                  \n__________________________________________________________________________________________________\nconv2d_65 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_64[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_65 (BatchNo (None, 335, 4, 64)   256         conv2d_65[0][0]                  \n__________________________________________________________________________________________________\nadd_32 (Add)                    (None, 335, 4, 64)   0           batch_normalization_65[0][0]     \n                                                                 activation_31[0][0]              \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 335, 4, 64)   0           add_32[0][0]                     \n__________________________________________________________________________________________________\nconv2d_66 (Conv2D)              (None, 335, 4, 64)   16448       activation_32[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_66 (BatchNo (None, 335, 4, 64)   256         conv2d_66[0][0]                  \n__________________________________________________________________________________________________\nconv2d_67 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_66[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_67 (BatchNo (None, 335, 4, 64)   256         conv2d_67[0][0]                  \n__________________________________________________________________________________________________\nadd_33 (Add)                    (None, 335, 4, 64)   0           batch_normalization_67[0][0]     \n                                                                 activation_32[0][0]              \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 335, 4, 64)   0           add_33[0][0]                     \n__________________________________________________________________________________________________\nconv2d_68 (Conv2D)              (None, 335, 4, 64)   16448       activation_33[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_68 (BatchNo (None, 335, 4, 64)   256         conv2d_68[0][0]                  \n__________________________________________________________________________________________________\nconv2d_69 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_68[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_69 (BatchNo (None, 335, 4, 64)   256         conv2d_69[0][0]                  \n__________________________________________________________________________________________________\nadd_34 (Add)                    (None, 335, 4, 64)   0           batch_normalization_69[0][0]     \n                                                                 activation_33[0][0]              \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 335, 4, 64)   0           add_34[0][0]                     \n__________________________________________________________________________________________________\nconv2d_70 (Conv2D)              (None, 335, 4, 64)   16448       activation_34[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_70 (BatchNo (None, 335, 4, 64)   256         conv2d_70[0][0]                  \n__________________________________________________________________________________________________\nconv2d_71 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_70[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_71 (BatchNo (None, 335, 4, 64)   256         conv2d_71[0][0]                  \n__________________________________________________________________________________________________\nadd_35 (Add)                    (None, 335, 4, 64)   0           batch_normalization_71[0][0]     \n                                                                 activation_34[0][0]              \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 335, 4, 64)   0           add_35[0][0]                     \n__________________________________________________________________________________________________\nconv2d_72 (Conv2D)              (None, 335, 4, 64)   16448       activation_35[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_72 (BatchNo (None, 335, 4, 64)   256         conv2d_72[0][0]                  \n__________________________________________________________________________________________________\nconv2d_73 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_72[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_73 (BatchNo (None, 335, 4, 64)   256         conv2d_73[0][0]                  \n__________________________________________________________________________________________________\nadd_36 (Add)                    (None, 335, 4, 64)   0           batch_normalization_73[0][0]     \n                                                                 activation_35[0][0]              \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 335, 4, 64)   0           add_36[0][0]                     \n__________________________________________________________________________________________________\nconv2d_74 (Conv2D)              (None, 335, 4, 64)   16448       activation_36[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_74 (BatchNo (None, 335, 4, 64)   256         conv2d_74[0][0]                  \n__________________________________________________________________________________________________\nconv2d_75 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_74[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_75 (BatchNo (None, 335, 4, 64)   256         conv2d_75[0][0]                  \n__________________________________________________________________________________________________\nadd_37 (Add)                    (None, 335, 4, 64)   0           batch_normalization_75[0][0]     \n                                                                 activation_36[0][0]              \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 335, 4, 64)   0           add_37[0][0]                     \n__________________________________________________________________________________________________\nconv2d_76 (Conv2D)              (None, 335, 4, 64)   16448       activation_37[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_76 (BatchNo (None, 335, 4, 64)   256         conv2d_76[0][0]                  \n__________________________________________________________________________________________________\nconv2d_77 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_76[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_77 (BatchNo (None, 335, 4, 64)   256         conv2d_77[0][0]                  \n__________________________________________________________________________________________________\nadd_38 (Add)                    (None, 335, 4, 64)   0           batch_normalization_77[0][0]     \n                                                                 activation_37[0][0]              \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 335, 4, 64)   0           add_38[0][0]                     \n__________________________________________________________________________________________________\nconv2d_78 (Conv2D)              (None, 335, 4, 64)   16448       activation_38[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_78 (BatchNo (None, 335, 4, 64)   256         conv2d_78[0][0]                  \n__________________________________________________________________________________________________\nconv2d_79 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_78[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_79 (BatchNo (None, 335, 4, 64)   256         conv2d_79[0][0]                  \n__________________________________________________________________________________________________\nadd_39 (Add)                    (None, 335, 4, 64)   0           batch_normalization_79[0][0]     \n                                                                 activation_38[0][0]              \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 335, 4, 64)   0           add_39[0][0]                     \n__________________________________________________________________________________________________\nLayer-4 (Conv2D)                (None, 334, 3, 64)   16448       activation_39[0][0]              \n__________________________________________________________________________________________________\nLayer-3 (GlobalAveragePooling2D (None, 64)           0           Layer-4[0][0]                    \n__________________________________________________________________________________________________\nLayer-2 (Dense)                 (None, 256)          16640       Layer-3[0][0]                    \n__________________________________________________________________________________________________\nLayer-1 (Dropout)               (None, 256)          0           Layer-2[0][0]                    \n__________________________________________________________________________________________________\nOutput_Layer (Dense)            (None, 1)            257         Layer-1[0][0]                    \n==================================================================================================\nTotal params: 375,841\nTrainable params: 373,281\nNon-trainable params: 2,560\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Layer to be used as an entry point into a Network (a graph of layers).\n",
    "# https://keras.io/api/layers/core_layers/input/\n",
    "inputs = keras.Input(shape=(672, 10, 1), name=\"Input_Layer\")\n",
    "# inputs = layers.InputLayer(input_shape=(672, 10), name=\"Input_Layer\")\n",
    "\n",
    "# 2D convolution layer (e.g. spatial convolution over images).\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "# filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "# kernel_size: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window.\n",
    "x = layers.Conv2D(32, 2, activation='relu', name=\"Layer01\")(inputs)\n",
    "x = layers.Conv2D(64, 2, activation='relu', name=\"Layer02\")(x)\n",
    "\n",
    "# Max pooling operation for 2D spatial data.\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D\n",
    "# pool_size: integer or tuple of 2 integers, window size over which to take the maximum.\n",
    "x = layers.MaxPooling2D(2, name=\"Layer03\")(x)\n",
    "\n",
    "num_res_net_blocks = 10 # 10个ResNet blocks\n",
    "for i in range(num_res_net_blocks):\n",
    "    x = res_net_block(64, 2, x)\n",
    "\n",
    "# [Final layers] a standard CNN layer\n",
    "x = layers.Conv2D(64, 2, activation='relu', name=\"Layer-4\")(x)\n",
    "# [Final layers] GAP layer\n",
    "x = layers.GlobalAveragePooling2D(name=\"Layer-3\")(x)\n",
    "# [Final layers] dense classification layers\n",
    "# Just your regular densely-connected NN layer.\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "# units: Positive integer, dimensionality of the output space.\n",
    "x = layers.Dense(256, activation='relu', name=\"Layer-2\")(x)\n",
    "# [Final layers] dropout layer\n",
    "x = layers.Dropout(0.5, name=\"Layer-1\")(x)\n",
    "# [Final layers] dense classification layers\n",
    "outputs = layers.Dense(1, activation='softmax', name=\"Output_Layer\")(x)\n",
    "res_net_model = keras.Model(inputs, outputs)\n",
    "\n",
    "res_net_model.summary()\n"
   ]
  },
  {
   "source": [
    "## 训练模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ERROR:tensorflow:Failed to start profiler: Another profiler is running.\n",
      "Epoch 1/30\n",
      "  1/195 [..............................] - ETA: 11:09 - loss: 52036.8242 - acc: 0.0000e+00WARNING:tensorflow:Trace already enabled\n",
      "ERROR:tensorflow:Failed to start profiler: Another profiler is running.\n",
      "195/195 [==============================] - 189s 954ms/step - loss: 3335.4480 - acc: 0.1080 - val_loss: 367.8030 - val_acc: 0.2917\n",
      "Epoch 2/30\n",
      " 13/195 [=>............................] - ETA: 2:50 - loss: 390.5171 - acc: 0.1058"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6e63f9a22560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m res_net_model.fit(train_dataset, epochs=30, steps_per_epoch=195,\n\u001b[1;32m     11\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m           validation_steps=3, callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "callbacks = [\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  keras.callbacks.TensorBoard(log_dir='./log/{}'.format(\n",
    "      dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")), write_images=True),\n",
    "  ]\n",
    "res_net_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "res_net_model.fit(train_dataset, epochs=30, steps_per_epoch=195,\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}