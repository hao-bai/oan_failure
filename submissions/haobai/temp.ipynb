{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集概览\n",
    "## Load datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(formatter={\"float\":lambda x: \"{:.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Optical Dataset composed of\n",
      "46110 source samples\n",
      "50862 source background samples\n",
      "438 target labeled samples\n",
      "8202 target unlabeled samples\n",
      "29592 target background samples\n",
      " Optical Dataset labels composed of\n",
      "46110 labels of source samples\n",
      "438 labels of target samples\n",
      "\n",
      "Test data\n",
      "Optical Dataset composed of\n",
      "0 source samples\n",
      "0 source background samples\n",
      "17758 target labeled samples\n",
      "0 target unlabeled samples\n",
      "47275 target background samples\n",
      " Optical Dataset labels composed of\n",
      "0 labels of source samples\n",
      "17758 labels of target samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from load import load_all_dataset\n",
    "X_train, y_train, X_test, y_test = load_all_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集\n",
    "### City A (source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source labeled (City A weak & failure): (46110, 672, 10)\n",
      "|- labels: (46110,)\n",
      " |- weak=0: (41341,)\n",
      " |- failure=1: (4769,)\n",
      "source background (City A good): (50862, 672, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"source labeled (City A weak & failure):\", X_train.source.shape)\n",
    "# print(np.where(np.isnan(X_train.source[0])))\n",
    "print(\"|- labels:\", y_train.source.shape)\n",
    "print(\" |- weak=0:\", y_train.source[y_train.source==0].shape)\n",
    "print(\" |- failure=1:\", y_train.source[y_train.source==1].shape)\n",
    "print(\"source background (City A good):\", X_train.source_bkg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City B (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target labeled (City B weak & failure): (438, 672, 10)\n",
      "|- labels: (438,)\n",
      " |- weak=0: (349,)\n",
      " |- failure=1: (89,)\n",
      "target background (City B good): (29592, 672, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"target labeled (City B weak & failure):\", X_train.target.shape)\n",
    "print(\"|- labels:\", y_train.target.shape)\n",
    "print(\" |- weak=0:\", y_train.target[y_train.target==0].shape)\n",
    "print(\" |- failure=1:\", y_train.target[y_train.target==1].shape)\n",
    "print(\"target background (City B good):\", X_train.target_bkg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集\n",
    "### City B (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target labeled (City B weak & failure): (17758, 672, 10)\n",
      "|- labels: (17758,)\n",
      " |- weak=0: (15464,)\n",
      " |- failure=1: (2294,)\n",
      "target background (City B good): (47275, 672, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"target labeled (City B weak & failure):\", X_test.target.shape)\n",
    "print(\"|- labels:\", y_test.target.shape)\n",
    "print(\" |- weak=0:\", y_test.target[y_test.target==0].shape)\n",
    "print(\" |- failure=1:\", y_test.target[y_test.target==1].shape)\n",
    "print(\"target background (City B good):\", X_test.target_bkg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Neural Network\n",
    "## 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46110, 672, 10, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去除NaN\n",
    "from feature_extractor import FeatureExtractor\n",
    "from numpy import newaxis\n",
    "class FE(FeatureExtractor):\n",
    "    def transform(self, X):\n",
    "        np.nan_to_num(X, copy=False)\n",
    "        return X[:,:,:,newaxis]\n",
    "\n",
    "fe = FE()\n",
    "X_train.source = fe.transform(X_train.source)\n",
    "X_train.target = fe.transform(X_train.target)\n",
    "X_test.target = fe.transform(X_test.target)\n",
    "X_train.source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集转换为TensorFlow格式\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train.source, y_train.source)).batch(16)\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((X_train.target, y_train.target)).batch(16)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test.target, y_test.target))\n",
    "\n",
    "# 额外操作\n",
    "train_dataset = train_dataset.map( lambda x, y: (tf.image.random_flip_left_right(x), y) )\n",
    "train_dataset = train_dataset.repeat()\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[0.000]\n"
     ]
    }
   ],
   "source": [
    "from numpy import zeros, newaxis\n",
    "a= zeros((4,3))\n",
    "print(a[0][0])\n",
    "b=a[:,:,newaxis]\n",
    "print(b[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建网络模型\n",
    "参考资料\n",
    "\n",
    "1. [Introduction to ResNet in TensorFlow 2](https://adventuresinmachinelearning.com/introduction-resnet-tensorflow-2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_net_block(filters, conv_size, input_data):\n",
    "    ''' A residual block of 3 layers\n",
    "    '''\n",
    "    # 1st layer with batch normalization\n",
    "    x = layers.Conv2D(filters, conv_size, activation='relu', padding='same')(input_data)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # 2nd layer with batch normalization, but no activation function\n",
    "    x = layers.Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # 3rd layer is residual addition with an activation function\n",
    "    x = layers.Add()([x, input_data])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Layer (InputLayer)        [(None, 672, 10, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Layer01 (Conv2D)                (None, 671, 9, 32)   160         Input_Layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Layer02 (Conv2D)                (None, 670, 8, 64)   8256        Layer01[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Layer03 (MaxPooling2D)          (None, 335, 4, 64)   0           Layer02[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 335, 4, 64)   16448       Layer03[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 335, 4, 64)   256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 335, 4, 64)   16448       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 335, 4, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 335, 4, 64)   0           batch_normalization_1[0][0]      \n",
      "                                                                 Layer03[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 335, 4, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 335, 4, 64)   16448       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 335, 4, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 335, 4, 64)   16448       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 335, 4, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 335, 4, 64)   0           batch_normalization_3[0][0]      \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 335, 4, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 335, 4, 64)   16448       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 335, 4, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 335, 4, 64)   16448       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 335, 4, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 335, 4, 64)   0           batch_normalization_5[0][0]      \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 335, 4, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 335, 4, 64)   16448       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 335, 4, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 335, 4, 64)   16448       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 335, 4, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 335, 4, 64)   0           batch_normalization_7[0][0]      \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 335, 4, 64)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 335, 4, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 335, 4, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 335, 4, 64)   16448       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 335, 4, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 335, 4, 64)   0           batch_normalization_9[0][0]      \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 335, 4, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 335, 4, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 335, 4, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 335, 4, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 335, 4, 64)   0           batch_normalization_11[0][0]     \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 335, 4, 64)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 335, 4, 64)   16448       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 335, 4, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 335, 4, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 335, 4, 64)   0           batch_normalization_13[0][0]     \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 335, 4, 64)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 335, 4, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 335, 4, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 335, 4, 64)   256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 335, 4, 64)   0           batch_normalization_15[0][0]     \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 335, 4, 64)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 335, 4, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 335, 4, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 335, 4, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 335, 4, 64)   0           batch_normalization_17[0][0]     \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 335, 4, 64)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 335, 4, 64)   16448       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 335, 4, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 335, 4, 64)   16448       batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 335, 4, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 335, 4, 64)   0           batch_normalization_19[0][0]     \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 335, 4, 64)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Layer-4 (Conv2D)                (None, 334, 3, 64)   16448       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Layer-3 (GlobalAveragePooling2D (None, 64)           0           Layer-4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Layer-2 (Dense)                 (None, 256)          16640       Layer-3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Layer-1 (Dropout)               (None, 256)          0           Layer-2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Output_Layer (Dense)            (None, 1)            257         Layer-1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 375,841\n",
      "Trainable params: 373,281\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Layer to be used as an entry point into a Network (a graph of layers).\n",
    "# https://keras.io/api/layers/core_layers/input/\n",
    "inputs = keras.Input(shape=(672, 10, 1), name=\"Input_Layer\")\n",
    "# inputs = layers.InputLayer(input_shape=(672, 10), name=\"Input_Layer\")\n",
    "\n",
    "# 2D convolution layer (e.g. spatial convolution over images).\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "# filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "# kernel_size: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window.\n",
    "x = layers.Conv2D(32, 2, activation='relu', name=\"Layer01\")(inputs)\n",
    "x = layers.Conv2D(64, 2, activation='relu', name=\"Layer02\")(x)\n",
    "\n",
    "# Max pooling operation for 2D spatial data.\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D\n",
    "# pool_size: integer or tuple of 2 integers, window size over which to take the maximum.\n",
    "x = layers.MaxPooling2D(2, name=\"Layer03\")(x)\n",
    "\n",
    "num_res_net_blocks = 10 # 10个ResNet blocks\n",
    "for i in range(num_res_net_blocks):\n",
    "    x = res_net_block(64, 2, x)\n",
    "\n",
    "# [Final layers] a standard CNN layer\n",
    "x = layers.Conv2D(64, 2, activation='relu', name=\"Layer-4\")(x)\n",
    "# [Final layers] GAP layer\n",
    "x = layers.GlobalAveragePooling2D(name=\"Layer-3\")(x)\n",
    "# [Final layers] dense classification layers\n",
    "# Just your regular densely-connected NN layer.\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "# units: Positive integer, dimensionality of the output space.\n",
    "x = layers.Dense(256, activation='relu', name=\"Layer-2\")(x)\n",
    "# [Final layers] dropout layer\n",
    "x = layers.Dropout(0.5, name=\"Layer-1\")(x)\n",
    "# [Final layers] dense classification layers\n",
    "outputs = layers.Dense(1, activation='softmax', name=\"Output_Layer\")(x)\n",
    "res_net_model = keras.Model(inputs, outputs)\n",
    "\n",
    "res_net_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbai/anaconda3/envs/huawei/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "195/195 [==============================] - 43s 206ms/step - loss: 4033.3296 - acc: 0.1080 - val_loss: 138.0643 - val_acc: 0.2917\n",
      "Epoch 2/30\n",
      "195/195 [==============================] - 39s 201ms/step - loss: 2266.7273 - acc: 0.0929 - val_loss: 680.8731 - val_acc: 0.2917\n",
      "Epoch 3/30\n",
      "195/195 [==============================] - 39s 202ms/step - loss: 3024.5115 - acc: 0.0801 - val_loss: 988.6604 - val_acc: 0.2917\n",
      "Epoch 4/30\n",
      "195/195 [==============================] - 39s 199ms/step - loss: 3166.4900 - acc: 0.0811 - val_loss: 2991.0842 - val_acc: 0.2917\n",
      "Epoch 5/30\n",
      "195/195 [==============================] - 40s 204ms/step - loss: 10994.6162 - acc: 0.0779 - val_loss: 649.6336 - val_acc: 0.2917\n",
      "Epoch 6/30\n",
      "195/195 [==============================] - 39s 202ms/step - loss: 905.0751 - acc: 0.0788 - val_loss: 2907.8586 - val_acc: 0.2917\n",
      "Epoch 7/30\n",
      "195/195 [==============================] - 40s 203ms/step - loss: 1793.6572 - acc: 0.0753 - val_loss: 88.3346 - val_acc: 0.2917\n",
      "Epoch 8/30\n",
      "195/195 [==============================] - 39s 202ms/step - loss: 2151.3362 - acc: 0.0891 - val_loss: 341.5120 - val_acc: 0.2917\n",
      "Epoch 9/30\n",
      "195/195 [==============================] - 39s 199ms/step - loss: 2212.9985 - acc: 0.1029 - val_loss: 960.1436 - val_acc: 0.2917\n",
      "Epoch 10/30\n",
      "195/195 [==============================] - 40s 204ms/step - loss: 1527.6532 - acc: 0.1157 - val_loss: 841.4472 - val_acc: 0.2917\n",
      "Epoch 11/30\n",
      "195/195 [==============================] - 39s 200ms/step - loss: 6237.8887 - acc: 0.1228 - val_loss: 935.3980 - val_acc: 0.2917\n",
      "Epoch 12/30\n",
      "195/195 [==============================] - 39s 202ms/step - loss: 1095.8953 - acc: 0.1288 - val_loss: 401.9427 - val_acc: 0.2917\n",
      "Epoch 13/30\n",
      "195/195 [==============================] - 39s 198ms/step - loss: 775.2077 - acc: 0.1295 - val_loss: 12.5115 - val_acc: 0.2917\n",
      "Epoch 14/30\n",
      "195/195 [==============================] - 40s 203ms/step - loss: 980.1109 - acc: 0.1356 - val_loss: 140.7549 - val_acc: 0.2917\n",
      "Epoch 15/30\n",
      "195/195 [==============================] - 39s 198ms/step - loss: 1179.7634 - acc: 0.1350 - val_loss: 51.8430 - val_acc: 0.2917\n",
      "Epoch 16/30\n",
      "195/195 [==============================] - 38s 196ms/step - loss: 750.5732 - acc: 0.1042 - val_loss: 60.7755 - val_acc: 0.2917\n",
      "Epoch 17/30\n",
      "195/195 [==============================] - 38s 196ms/step - loss: 45.8315 - acc: 0.0901 - val_loss: 176.3682 - val_acc: 0.2917\n",
      "Epoch 18/30\n",
      "195/195 [==============================] - 38s 195ms/step - loss: 188.5260 - acc: 0.0782 - val_loss: 55.5944 - val_acc: 0.2917\n",
      "Epoch 19/30\n",
      "195/195 [==============================] - 38s 196ms/step - loss: 169.5171 - acc: 0.0853 - val_loss: 54.1200 - val_acc: 0.2917\n",
      "Epoch 20/30\n",
      "195/195 [==============================] - 38s 196ms/step - loss: 73.4612 - acc: 0.0772 - val_loss: 3.4403 - val_acc: 0.2917\n",
      "Epoch 21/30\n",
      "195/195 [==============================] - 39s 202ms/step - loss: 103.8407 - acc: 0.0737 - val_loss: 197.9806 - val_acc: 0.2917\n",
      "Epoch 22/30\n",
      "195/195 [==============================] - 39s 198ms/step - loss: 2073.3457 - acc: 0.0785 - val_loss: 117.8705 - val_acc: 0.2917\n",
      "Epoch 23/30\n",
      "195/195 [==============================] - 38s 196ms/step - loss: 158.5634 - acc: 0.0920 - val_loss: 110.3181 - val_acc: 0.2917\n",
      "Epoch 24/30\n",
      "195/195 [==============================] - 39s 201ms/step - loss: 254.3068 - acc: 0.1054 - val_loss: 720.6155 - val_acc: 0.2917\n",
      "Epoch 25/30\n",
      "195/195 [==============================] - 39s 202ms/step - loss: 199.8222 - acc: 0.1189 - val_loss: 109.0390 - val_acc: 0.2917\n",
      "Epoch 26/30\n",
      "195/195 [==============================] - 39s 199ms/step - loss: 103.9038 - acc: 0.1244 - val_loss: 1268.7245 - val_acc: 0.2917\n",
      "Epoch 27/30\n",
      "195/195 [==============================] - 38s 196ms/step - loss: 262.8450 - acc: 0.1314 - val_loss: 13.9332 - val_acc: 0.2917\n",
      "Epoch 28/30\n",
      "195/195 [==============================] - 40s 203ms/step - loss: 56.0000 - acc: 0.1272 - val_loss: 21.8041 - val_acc: 0.2917\n",
      "Epoch 29/30\n",
      "195/195 [==============================] - 40s 203ms/step - loss: 0.9921 - acc: 0.1365 - val_loss: 2.6159 - val_acc: 0.2917\n",
      "Epoch 30/30\n",
      "195/195 [==============================] - 39s 199ms/step - loss: 4.6663 - acc: 0.1296 - val_loss: 18.4727 - val_acc: 0.2917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbe281f7520>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "callbacks = [\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  keras.callbacks.TensorBoard(log_dir='./log/{}'.format(\n",
    "      dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")), write_images=True),\n",
    "  ]\n",
    "res_net_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "res_net_model.fit(train_dataset, epochs=30, steps_per_epoch=195,\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "77a176e6d68c62f570691917117cf1b3298ba06ea1b936eeef71e844f28195b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('huawei': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}