{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用数据集的统计特征（statistics of dataset）作为输入\n",
    "## 预处理\n",
    "### 装载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.seterr(all='warn')\n",
    "import warnings\n",
    "from scipy import stats\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        `X`: ndarray of (sample, 672, 10)\n",
    "            3D input dataset(sample, time, features)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        `X`: ndarray of (sample, 6720)\n",
    "            The filtered dataset\n",
    "        '''\n",
    "        X = X.astype(np.float64)\n",
    "        tmp_X = []\n",
    "        for x in X:\n",
    "            # 处理NaN数据\n",
    "            x[:, np.all(~np.isfinite(x), axis=0)] = 0 # 用0填充全部是NaN的列\n",
    "            # ------------------------------------------------------------------\n",
    "            # 计算统计量\n",
    "            _ = []\n",
    "            # There is a bug in `np.nanpercentile` which computes very slow\n",
    "            if np.any(~np.isfinite(x)) == True:\n",
    "                b = []\n",
    "                for row in x.T:\n",
    "                    tmp = row[np.isfinite(row)]\n",
    "                    pct = np.percentile(tmp, [25, 50, 75])\n",
    "                    b.append(pct)\n",
    "                b = np.array(b).T\n",
    "            else:\n",
    "                b = np.percentile(x, [25, 50, 75], axis=0)\n",
    "            _.append( b[0] ) # 一分位数@25\n",
    "            _.append( b[1] ) # 二分位数\n",
    "            _.append( b[2] ) # 三分位数@75\n",
    "\n",
    "            # with warnings.catch_warnings():\n",
    "            #     warnings.filterwarnings('error')\n",
    "            #     try:\n",
    "            _.append( np.nanmean(x, axis=0) ) # 均值\n",
    "            _.append( np.nanstd(x, axis=0)) # 标准差\n",
    "            _.append( np.nanmax(x, axis=0) ) # 最大值\n",
    "            _.append( np.nanmin(x, axis=0) ) # 最小值\n",
    "            _.append( stats.mode(x, axis=0, nan_policy=\"omit\")[0][0]) # 众数\n",
    "            _.append( stats.kurtosis(x, axis=0, nan_policy=\"omit\", fisher=False)) # 峰度 # RuntimeWarning: overflow => change type to np.float64\n",
    "            _.append( stats.skew(x, axis=0, nan_policy=\"omit\")) # 偏度\n",
    "            _.append( np.sum(np.isfinite(x), axis=0)/x.shape[0] ) # 有效值数量占比\n",
    "                # except Warning as e:\n",
    "                #     print(\"x is\", x.shape)\n",
    "                #     print(\"_ is\", len(_))\n",
    "                #     TEST = x\n",
    "                #     raise e\n",
    "            # ------------------------------------------------------------------\n",
    "            # 加入第3维数组\n",
    "            tmp_X.append( np.array(_) )\n",
    "            # tmp_X.append( x )\n",
    "        X = np.array(tmp_X)\n",
    "\n",
    "        # flatten\n",
    "        # X = X.reshape(X.shape[0], -1) # required for outlier detection\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. 读取原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from others import load_all_dataset, rename_dataset\n",
    "X_train, y_train, X_test, y_test = load_all_dataset(show=False)\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems=5,\n",
    "                    linewidth=1000,\n",
    "                    formatter={\"float\":lambda x: \"{:.3f}\".format(x)})\n",
    "\n",
    "fe = FeatureExtractor()\n",
    "# X_source = fe.transform(X_train.source)\n",
    "# np.all(np.isfinite(X_source)) # expected True\n",
    "[X_source, X_source_bkg, X_target, X_target_unlabeled, X_target_bkg,\n",
    "    y_source, y_target, X_test] = rename_dataset(\n",
    "    fe, X_train, y_train, X_test, y_test, show_imbalance=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 读取统计数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把统计数值保存到硬盘，已检查所有array里面的数值都是finite\n",
    "# np.save(\"./data_stats/X_source\", X_source)\n",
    "# np.save(\"./data_stats/X_source_bkg\", X_source_bkg)\n",
    "# np.save(\"./data_stats/X_target\", X_target)\n",
    "# np.save(\"./data_stats/X_target_unlabeled\", X_target_unlabeled)\n",
    "# np.save(\"./data_stats/X_target_bkg\", X_target_bkg)\n",
    "# np.save(\"./data_stats/y_source\", y_source)\n",
    "# np.save(\"./data_stats/y_target\", y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_source = np.load(\"./data_stats/X_source.npy\")\n",
    "X_source_bkg = np.load(\"./data_stats/X_source_bkg.npy\")\n",
    "X_target = np.load(\"./data_stats/X_target.npy\")\n",
    "X_target_unlabeled = np.load(\"./data_stats/X_target_unlabeled.npy\")\n",
    "X_target_bkg = np.load(\"./data_stats/X_target_bkg.npy\")\n",
    "y_source = np.load(\"./data_stats/y_source.npy\")\n",
    "y_target = np.load(\"./data_stats/y_target.npy\")\n",
    "\n",
    "fe = FeatureExtractor()\n",
    "X_test.target = fe.transform(X_test.target)\n",
    "X_test.target_bkg = fe.transform(X_test.target_bkg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整理数据（Normalization, Oversampling, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_source = X_source.reshape(X_source.shape[0], -1)\n",
    "X_source_bkg = X_source_bkg.reshape(X_source_bkg.shape[0], -1)\n",
    "X_target = X_target.reshape(X_target.shape[0], -1)\n",
    "X_target_unlabeled = X_target_unlabeled.reshape(X_target_unlabeled.shape[0], -1)\n",
    "X_target_bkg = X_target_bkg.reshape(X_target_bkg.shape[0], -1)\n",
    "X_test.target = X_test.target.reshape(X_test.target.shape[0], -1)\n",
    "X_test.target_bkg = X_test.target_bkg.reshape(X_test.target_bkg.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_RF = RandomForestClassifier(\n",
    "    n_estimators=2, max_depth=2, random_state=44, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_DT.fit(X_source, y_source)\n",
    "model_RF.fit(X_source, y_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(\"X_test.target.shape:\", X_test.target.shape)\n",
    "\n",
    "print(\"[train: B] Random Forest:\", model_RF.score(X_target, y_target))\n",
    "print(\"[test:  B] Random Forest:\", model_RF.score(X_test.target, y_test.target))\n",
    "y_pred = model_RF.predict(X_test.target)\n",
    "print(\"Predicted:\", Counter(y_pred), y_pred.shape)\n",
    "print(\"True:      \", Counter(y_test.target), y_test.target.shape)\n",
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检验模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Test data\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "-------------------------------------\n",
      "training ap on fold 0 = 0.410\n",
      "validation ap on fold 0 = 0.357\n",
      "test ap on fold 0 = 0.230\n",
      "Test data\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "-------------------------------------\n",
      "training ap on fold 1 = 0.707\n",
      "validation ap on fold 1 = 0.363\n",
      "test ap on fold 1 = 0.233\n",
      "Test data\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "-------------------------------------\n",
      "training ap on fold 2 = 0.267\n",
      "validation ap on fold 2 = 0.366\n",
      "test ap on fold 2 = 0.232\n",
      "Test data\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "Should be True:  True\n",
      "-------------------------------------\n",
      "training ap on fold 3 = 0.625\n",
      "validation ap on fold 3 = 0.361\n",
      "test ap on fold 3 = 0.218\n",
      "Test data\n",
      "-------------------------------------\n",
      "training ap on fold 4 = 0.583\n",
      "validation ap on fold 4 = 0.359\n",
      "test ap on fold 4 = 0.237\n",
      "Test data\n",
      "-------------------------------------\n",
      "training ap on fold 5 = 0.533\n",
      "validation ap on fold 5 = 0.373\n",
      "test ap on fold 5 = 0.229\n",
      "Test data\n",
      "-------------------------------------\n",
      "training ap on fold 6 = 0.229\n",
      "validation ap on fold 6 = 0.365\n",
      "test ap on fold 6 = 0.226\n",
      "Test data\n",
      "-------------------------------------\n",
      "training ap on fold 7 = 0.444\n",
      "validation ap on fold 7 = 0.345\n",
      "test ap on fold 7 = 0.218\n",
      "Test data\n",
      "-------------------------------------\n",
      "training ap on fold 8 = 0.475\n",
      "validation ap on fold 8 = 0.357\n",
      "test ap on fold 8 = 0.230\n",
      "Test data\n",
      "-------------------------------------\n",
      "training ap on fold 9 = 0.365\n",
      "validation ap on fold 9 = 0.361\n",
      "test ap on fold 9 = 0.233\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ap_bagged_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a8e67a623458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# 计算排名指标: bagged average precision on test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m ap_bagged_test.append(\n\u001b[0m\u001b[1;32m     41\u001b[0m     ap(y_test.target, np.array([y_test_pred for y_test_pred in y_test_preds]).mean(axis=0)[:,1]))\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}: Bagged ap score = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0map_bagged_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ap_bagged_test' is not defined"
     ]
    }
   ],
   "source": [
    "import rampwf as rw\n",
    "import numpy as np\n",
    "from others import cd\n",
    "\n",
    "# 载入数据\n",
    "with cd(\"~/Codes/HuaweiRAMP\"):\n",
    "    problem = rw.utils.assert_read_problem()\n",
    "    X_train, y_train = problem.get_train_data(show=False)\n",
    "    \n",
    "# 导入评价函数\n",
    "ap    = problem.score_types[0]\n",
    "# 设置crossvalidation\n",
    "splits = problem.get_cv(X_train, y_train, n_splits=10) # 默认10\n",
    "\n",
    "# 开始实验\n",
    "ap_train, ap_valid, ap_test, = [], [], []\n",
    "y_test_preds = []\n",
    "for fold_i, (train_is, valid_is) in enumerate(splits):\n",
    "    with cd(\"~/Codes/HuaweiRAMP\"):\n",
    "        X_test, y_test = problem.get_test_data(show=False)\n",
    "    trained_workflow = problem.workflow.train_submission(\n",
    "        '.', X_train, y_train, train_is,)\n",
    "    X_fold_train = X_train.slice(train_is)\n",
    "    X_fold_valid = X_train.slice(valid_is)\n",
    "    \n",
    "    y_train_pred = problem.workflow.test_submission(trained_workflow, X_fold_train)\n",
    "    y_valid_pred = problem.workflow.test_submission(trained_workflow, X_fold_valid)\n",
    "    y_test_pred = problem.workflow.test_submission(trained_workflow, X_test)\n",
    "    ap_train.append( ap(y_train.slice(train_is).target, y_train_pred[:,1]) )\n",
    "    ap_valid.append( ap(y_train.slice(valid_is).target, y_valid_pred[:,1]) )\n",
    "    ap_test.append( ap(y_test.target, y_test_pred[:,1]) )\n",
    "    print('-------------------------------------')\n",
    "    print('training ap on fold {} = {:.3f}'.format(fold_i, ap_train[-1]))\n",
    "    print('validation ap on fold {} = {:.3f}'.format(fold_i, ap_valid[-1]))\n",
    "    print('test ap on fold {} = {:.3f}'.format(fold_i, ap_test[-1]))\n",
    "    \n",
    "    y_test_preds.append(y_test_pred)\n",
    "\n",
    "# 计算排名指标: bagged average precision on test dataset\n",
    "score = ap(y_test.target, np.array([y_test_pred for y_test_pred in y_test_preds]).mean(axis=0)[:,1])\n",
    "ap_bagged_test.append(score)\n",
    "print('{}: Bagged ap score = {}'.format(ss, ap_bagged_test[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24449585291126194"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调试超参\n",
    "直接使用华为提供的比赛工具包来评价模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rampwf as rw\n",
    "import numpy as np\n",
    "from others import cd\n",
    "\n",
    "hp_range = np.arange(0.2, 1.1, 0.1)\n",
    "ap_bagged_test = []\n",
    "\n",
    "for ss in hp_range:\n",
    "    # 载入数据\n",
    "    with cd(\"~/Codes/HuaweiRAMP\"):\n",
    "        problem = rw.utils.assert_read_problem()\n",
    "        X_train, y_train = problem.get_train_data(show=False)\n",
    "        X_test, y_test = problem.get_test_data(show=False)\n",
    "    # 导入评价函数\n",
    "    ap    = problem.score_types[0]\n",
    "    # 设置crossvalidation\n",
    "    splits = problem.get_cv(X_train, y_train, n_splits=10) # 默认10\n",
    "    # 开始实验\n",
    "    ap_train, ap_valid, ap_test, = [], [], []\n",
    "    y_test_preds = []\n",
    "    for fold_i, (train_is, valid_is) in enumerate(splits):\n",
    "        trained_workflow = problem.workflow.train_submission(\n",
    "            '.', X_train, y_train, train_is, sampling_strategy=ss)\n",
    "        X_fold_train = X_train.slice(train_is)\n",
    "        X_fold_valid = X_train.slice(valid_is)\n",
    "        \n",
    "        y_train_pred = problem.workflow.test_submission(trained_workflow, X_fold_train)\n",
    "        y_valid_pred = problem.workflow.test_submission(trained_workflow, X_fold_valid)\n",
    "        y_test_pred = problem.workflow.test_submission(trained_workflow, X_test)\n",
    "        ap_train.append( ap(y_train.slice(train_is).target, y_train_pred[:,1]) )\n",
    "        ap_valid.append( ap(y_train.slice(valid_is).target, y_valid_pred[:,1]) )\n",
    "        ap_test.append( ap(y_test.target, y_test_pred[:,1]) )\n",
    "        # print('-------------------------------------')\n",
    "        # print('training ap on fold {} = {:.3f}'.format(fold_i, ap_train[-1]))\n",
    "        # print('validation ap on fold {} = {:.3f}'.format(fold_i, ap_valid[-1]))\n",
    "        # print('test ap on fold {} = {:.3f}'.format(fold_i, ap_test[-1]))\n",
    "        \n",
    "        y_test_preds.append(y_test_pred)\n",
    "\n",
    "    # 计算排名指标: bagged average precision on test dataset\n",
    "    ap_bagged_test.append(\n",
    "        ap(y_test.target, np.array([y_test_pred for y_test_pred in y_test_preds]).mean(axis=0)[:,1]))\n",
    "    print('{}: Bagged ap score = {}'.format(ss, ap_bagged_test[-1]))\n",
    "    del problem, X_train, y_train, X_test, y_test, ap, splits, y_test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots()\n",
    "fig.add_trace(go.Scatter(x=hp_range, y=ap_bagged_test, mode=\"lines\",\n",
    "                         name=\"sampling_strategy\"))\n",
    "fig.update_layout(xaxis_title=\"Hyperparameter\", yaxis_title=\"Bagged ap\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "77a176e6d68c62f570691917117cf1b3298ba06ea1b936eeef71e844f28195b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('huawei': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}