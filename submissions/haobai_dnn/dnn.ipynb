{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Deep Neural Network\n",
    "## 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Optical Dataset composed of\n",
      "46110 source samples\n",
      "50862 source background samples\n",
      "438 target labeled samples\n",
      "8202 target unlabeled samples\n",
      "29592 target background samples\n",
      " Optical Dataset labels composed of\n",
      "46110 labels of source samples\n",
      "438 labels of target samples\n",
      "\n",
      "Test data\n",
      "Optical Dataset composed of\n",
      "0 source samples\n",
      "0 source background samples\n",
      "17758 target labeled samples\n",
      "0 target unlabeled samples\n",
      "47275 target background samples\n",
      " Optical Dataset labels composed of\n",
      "0 labels of source samples\n",
      "17758 labels of target samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from others import load_all_dataset\n",
    "X_train, y_train, X_test, y_test = load_all_dataset()\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems=5,\n",
    "                    linewidth=1000,\n",
    "                    formatter={\"float\":lambda x: \"{:.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== TRAIN SET ====\n",
      "  | X_source: (46110, 6720) ; y_source: (46110,)\n",
      "A | X_source_bkg: (50862, 6720)\n",
      "----\n",
      "  | X_target: (438, 6720) ; y_target: (438,)\n",
      "B | X_target_bkg: (29592, 6720)\n",
      "  | X_target_unlabeled: (8202, 6720)\n",
      "==== TEST SET ====\n",
      "  | X_test.target: (17758, 6720) ; y_test.target: (17758,)\n",
      "B | X_test.target_bkg: (47275, 6720)\n",
      "  | X_test.target_unlabeled: None\n"
     ]
    }
   ],
   "source": [
    "# 去除NaN\n",
    "class FeatureExtractor:\n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        `X`: ndarray of (sample, 672, 10)\n",
    "            3D input dataset(sample, time, features)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        `X`: ndarray of (sample, 6720)\n",
    "            The filtered dataset\n",
    "        '''\n",
    "        np.nan_to_num(X, copy=False)\n",
    "        X = X.reshape(X.shape[0], -1)\n",
    "        return X\n",
    "\n",
    "fe = FeatureExtractor()\n",
    "\n",
    "# 重命名\n",
    "from copy import deepcopy\n",
    "# 训练集\n",
    "print(\"==== TRAIN SET ====\")\n",
    "X_source = deepcopy( fe.transform(X_train.source) )\n",
    "print(\"  | X_source:\", X_source.shape, end=\" ; \")\n",
    "y_source = deepcopy( y_train.source )\n",
    "print(\"y_source:\", y_source.shape)\n",
    "X_source_bkg = deepcopy( fe.transform(X_train.source_bkg) )\n",
    "print(\"A | X_source_bkg:\", X_source_bkg.shape)\n",
    "X_target = deepcopy( fe.transform(X_train.target) )\n",
    "print(\"----\")\n",
    "print(\"  | X_target:\", X_target.shape, end=\" ; \")\n",
    "y_target = deepcopy( y_train.target )\n",
    "print(\"y_target:\", y_target.shape)\n",
    "X_target_bkg= deepcopy( fe.transform(X_train.target_bkg) )\n",
    "print(\"B | X_target_bkg:\", X_target_bkg.shape)\n",
    "X_target_unlabeled = deepcopy( fe.transform(X_train.target_unlabeled) )\n",
    "print(\"  | X_target_unlabeled:\", X_target_unlabeled.shape)\n",
    "# 测试集\n",
    "print(\"==== TEST SET ====\")\n",
    "X_test.target = fe.transform(X_test.target)\n",
    "print(\"  | X_test.target:\", X_test.target.shape, end=\" ; \")\n",
    "print(\"y_test.target:\", y_test.target.shape)\n",
    "X_test.target_bkg = fe.transform(X_test.target_bkg)\n",
    "print(\"B | X_test.target_bkg:\", X_test.target_bkg.shape)\n",
    "print(\"  | X_test.target_unlabeled:\", X_test.target_unlabeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "笔记:\n",
    "- batch size 越大，同样多epoch下，acc 越小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集转换为TensorFlow格式\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_source, y_source)).batch(32)\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((X_target, y_target)).batch(32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test.target, y_test.target))\n",
    "\n",
    "# 额外操作\n",
    "# train_dataset = train_dataset.map( lambda x, y: (tf.image.random_flip_left_right(x), y) ) # array must be 3D\n",
    "train_dataset = train_dataset.repeat()\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建网络模型\n",
    "参考资料\n",
    "\n",
    "1. [Build your first Neural Network in TensorFlow 2](https://towardsdatascience.com/building-your-first-neural-network-in-tensorflow-2-tensorflow-for-hackers-part-i-e1e2f1dfe7a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential groups a linear stack of layers into a tf.keras.Model.\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "model = tf.keras.Sequential()\n",
    "model.add( layers.Flatten(input_shape=(6720,), name=\"Input_Layer\") )\n",
    "\n",
    "num_fully_connected_layers = 10\n",
    "for i in range(num_fully_connected_layers):\n",
    "    model.add( layers.Dense(256, activation=\"relu\", name=\"Layer{}\".format(i+1)) )\n",
    "\n",
    "model.add( layers.Dropout(0.5, name=\"Layer-1\"))\n",
    "model.add( layers.Dense(1, activation='sigmoid', name=\"Output_Layer\") )\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.Precision(),\n",
    "                       # tf.keras.metrics.PrecisionAtRecall(recall=0.1),\n",
    "                       \"acc\",\n",
    "                      ]\n",
    "             )\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "- if 'softmax' in the last layer, output is 0 or 1\n",
    "    - 'categorical_crossentropy' returns NaN, 'binary_crossentropy' acc ~ 0.1\n",
    "- if `'sigmoid'` in the last layer, output is the probability of 1\n",
    "    - 'categorical_crossentropy' returns NaN, `'binary_crossentropy'` acc ~ 0.8 to 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 1s 24ms/step - loss: 20785.7285 - precision: 0.1546 - acc: 0.6781 - val_loss: 20763.3203 - val_precision: 0.0000e+00 - val_acc: 0.6979\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 8220.7422 - precision: 0.1633 - acc: 0.7328 - val_loss: 12432.5635 - val_precision: 0.5000 - val_acc: 0.6979\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 164032.8438 - precision: 0.1626 - acc: 0.6719 - val_loss: 47673.1562 - val_precision: 0.0000e+00 - val_acc: 0.6979\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 44269.3711 - precision: 0.0941 - acc: 0.7750 - val_loss: 25850.3066 - val_precision: 0.0000e+00 - val_acc: 0.6979\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 12544.1348 - precision: 0.0792 - acc: 0.7828 - val_loss: 6078.7793 - val_precision: 0.0000e+00 - val_acc: 0.6979\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 11251.4736 - precision: 0.1077 - acc: 0.7437 - val_loss: 912.7089 - val_precision: 0.6364 - val_acc: 0.7292\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1119.0865 - precision: 0.1389 - acc: 0.7688 - val_loss: 1475.1675 - val_precision: 0.3750 - val_acc: 0.6771\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1608.9485 - precision: 0.1343 - acc: 0.7656 - val_loss: 3315.0012 - val_precision: 0.4828 - val_acc: 0.6875\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 3969.7310 - precision: 0.1576 - acc: 0.7406 - val_loss: 5081.5254 - val_precision: 0.5000 - val_acc: 0.6979\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 6643.8579 - precision: 0.1200 - acc: 0.8531 - val_loss: 9966.2666 - val_precision: 1.0000 - val_acc: 0.7083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f00ad9acfd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "callbacks = [\n",
    "    # Write TensorBoard logs to `./logs` directory\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./log/{}'.format(\n",
    "        dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M DNN\")), write_images=True),\n",
    "    ]\n",
    "model.fit(train_dataset, epochs=10, steps_per_epoch=20,\n",
    "          validation_data=valid_dataset, validation_steps=3,\n",
    "          # callbacks=callbacks\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.target.shape: (17758, 6720)\n",
      "Predicted: [[0.000 0.000 0.000 0.000 0.000 ... 0.000 0.002 0.000 0.000 0.001]] (1, 17758)\n",
      "True:       [0.000 0.000 0.000 0.000 0.000 ... 0.000 1.000 0.000 0.000 1.000] (17758,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test.target.shape:\", X_test.target.shape)\n",
    "# X = X_test.target.reshape(X_test.target.shape[0], -1)\n",
    "# print(X.shape)\n",
    "y_pred = model.predict(X_test.target).transpose()\n",
    "print(\"Predicted:\", y_pred, y_pred.shape)\n",
    "print(\"True:      \", y_test.target, y_test.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "77a176e6d68c62f570691917117cf1b3298ba06ea1b936eeef71e844f28195b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('huawei': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}