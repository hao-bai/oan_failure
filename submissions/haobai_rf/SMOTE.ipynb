{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Minority Oversampling Technique (SMOTE) for Imbalanced classification\n",
    "1. [Blog: SMOTE for Imbalanced Classification with Python](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)\n",
    "\n",
    "# Neural Architecture Search Network (NASNet)\n",
    "1. [Paper: Learning Transferable Architectures for Scalable Image Recognition](https://arxiv.org/abs/1707.07012)\n",
    "2. [Keras doc: NasNetLarge and NasNetMobile](https://keras.io/api/applications/nasnet/#nasnetlarge-function)\n",
    "\n",
    "## 预处理\n",
    "### 装载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Optical Dataset composed of\n",
      "46110 source samples\n",
      "50862 source background samples\n",
      "438 target labeled samples\n",
      "8202 target unlabeled samples\n",
      "29592 target background samples\n",
      " Optical Dataset labels composed of\n",
      "46110 labels of source samples\n",
      "438 labels of target samples\n",
      "\n",
      "Test data\n",
      "Optical Dataset composed of\n",
      "0 source samples\n",
      "0 source background samples\n",
      "17758 target labeled samples\n",
      "0 target unlabeled samples\n",
      "47275 target background samples\n",
      " Optical Dataset labels composed of\n",
      "0 labels of source samples\n",
      "17758 labels of target samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from others import load_all_dataset, rename_dataset\n",
    "X_train, y_train, X_test, y_test = load_all_dataset()\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems=5,\n",
    "                    linewidth=1000,\n",
    "                    formatter={\"float\":lambda x: \"{:.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rename_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bf23b1fb3777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m [X_source, X_source_bkg, X_target, X_target_unlabeled, X_target_bkg,\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0my_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrename_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     fe, X_train, y_train, X_test, y_test, show_imbalance=True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rename_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# 去除NaN\n",
    "from numpy import newaxis\n",
    "class FeatureExtractor:\n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        `X`: ndarray of (sample, 672, 10)\n",
    "            3D input dataset(sample, time, features)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        `X`: ndarray of (sample, 6720)\n",
    "            The filtered dataset\n",
    "        '''\n",
    "        np.nan_to_num(X, copy=False)\n",
    "        X = X.reshape(X.shape[0], -1)\n",
    "        return X\n",
    "\n",
    "fe = FeatureExtractor()\n",
    "[X_source, X_source_bkg, X_target, X_target_unlabeled, X_target_bkg,\n",
    "    y_source, y_target, X_test] = rename_dataset(\n",
    "    fe, X_train, y_train, X_test, y_test, show_imbalance=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整理数据（Normalization, Oversampling, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41340, 6720) (41340,)\n",
      "Counter({0.0: 20670, 1.0: 20670})\n"
     ]
    }
   ],
   "source": [
    "import imblearn as il\n",
    "from collections import Counter\n",
    "over = il.over_sampling.SMOTE(sampling_strategy=0.5) # minority/majority ratio\n",
    "X_source, y_source = over.fit_resample(X_source, y_source)\n",
    "\n",
    "under = il.under_sampling.RandomUnderSampler(sampling_strategy=1.0)\n",
    "X_source, y_source = under.fit_resample(X_source, y_source)\n",
    "\n",
    "print(X_source.shape, y_source.shape)\n",
    "print(Counter(y_source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_DT = DecisionTreeClassifier(max_depth=2, random_state=44,)\n",
    "model_RF = RandomForestClassifier(\n",
    "    n_estimators=2, max_depth=2, random_state=44, n_jobs=-1)\n",
    "\n",
    "# define pipeline\n",
    "# over = il.over_sampling.SMOTE(sampling_strategy=0.1)\n",
    "# under = il.under_sampling.RandomUnderSampler(sampling_strategy=0.5)\n",
    "# steps = [('over', over), ('under', under), ('model', model_DT)]\n",
    "# pipeline_DT = il.pipeline.Pipeline(steps=steps)\n",
    "\n",
    "# steps = [('over', over), ('under', under), ('model', model_RF)]\n",
    "# pipeline_RF = il.pipeline.Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, n_estimators=2, n_jobs=-1, random_state=44)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_DT.fit(X_source, y_source)\n",
    "model_RF.fit(X_source, y_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.target.shape: (17758, 6720)\n",
      "Decision Tree: 0.7054794520547946\n",
      "Decision Tree: 0.7059353530803019\n",
      "Predicted: Counter({0.0: 13356, 1.0: 4402}) (17758,)\n",
      "True:       Counter({0.0: 15464, 1.0: 2294}) (17758,)\n",
      "Random Forest: 0.7191780821917808\n",
      "Random Forest: 0.7348800540601419\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test.target.shape:\", X_test.target.shape)\n",
    "y_pred = model_DT.predict(X_test.target)\n",
    "print(\"Decision Tree:\", model_DT.score(X_target, y_target))\n",
    "print(\"Decision Tree:\", model_DT.score(X_test.target, y_test.target))\n",
    "print(\"Predicted:\", Counter(y_pred), y_pred.shape)\n",
    "print(\"True:      \", Counter(y_test.target), y_test.target.shape)\n",
    "\n",
    "print(\"Random Forest:\", model_RF.score(X_target, y_target))\n",
    "print(\"Random Forest:\", model_RF.score(X_test.target, y_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "77a176e6d68c62f570691917117cf1b3298ba06ea1b936eeef71e844f28195b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('huawei': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}