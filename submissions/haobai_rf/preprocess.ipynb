{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理探究\n",
    "## 装载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Test data\n"
     ]
    }
   ],
   "source": [
    "from others import load_all_dataset, rename_dataset\n",
    "X_train, y_train, X_test, y_test = load_all_dataset(show=False)\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems=5,\n",
    "                    linewidth=1000,\n",
    "                    formatter={\"float\":lambda x: \"{:.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaN值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== TRAIN SET ====\n",
      "Expected True: True\n",
      "  | X_source: (46110, 6048) ; y_source: (46110,)\n",
      "Expected True: True\n",
      "A | X_source_bkg: (50862, 6048)\n",
      "Expected True: True\n",
      "----\n",
      "  | X_target: (438, 6048) ; y_target: (438,)\n",
      "Expected True: True\n",
      "B | X_target_bkg: (29592, 6048)\n",
      "Expected True: True\n",
      "  | X_target_unlabeled: (8202, 6048)\n",
      "==== TEST SET ====\n",
      "Expected True: True\n",
      "  | X_test.target: (17758, 6048) ; y_test.target: (17758,)\n",
      "Expected True: True\n",
      "B | X_test.target_bkg: (47275, 6048)\n",
      "  | X_test.target_unlabeled: None\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        `X`: ndarray of (sample, 672, 10)\n",
    "            3D input dataset(sample, time, features)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        `X`: ndarray of (sample, 6720)\n",
    "            The filtered dataset\n",
    "        '''\n",
    "        X = np.delete(X, [3,], axis=2)\n",
    "        X = X.astype(np.float64)\n",
    "        \n",
    "        ## 1st round\n",
    "        X1, nanmean = [], []\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i]\n",
    "            indice = ~np.isfinite(x)\n",
    "            nanmean.append(np.nanmean(x, axis=0))\n",
    "\n",
    "            # Columns with full Nan\n",
    "            col_is_nan = np.all(indice, axis=0)\n",
    "            if (col_is_nan == True).any():\n",
    "                X1.append(x) # deal later\n",
    "                continue\n",
    "            \n",
    "            # Rows with full Nan\n",
    "            # Unachievable. Cause we don't have access to manipulate on labels\n",
    "            # row_is_nan = np.all(indice, axis=1)\n",
    "            # if (row_is_nan == True).any():\n",
    "            #     row = np.where(row_is_nan == True)[0]\n",
    "            #     if len(row) >= x.shape[0]/4: # drop sample, /2=85%+, /4=75%+\n",
    "            #         continue\n",
    "            \n",
    "            # Columns with partial NaN\n",
    "            part_is_nan = np.any(indice, axis=0)\n",
    "            if (part_is_nan == True).any():\n",
    "                col = np.where(part_is_nan == True)[0]\n",
    "                # part_nan[i] = col[0]\n",
    "                for c in col:\n",
    "                    this = x[:,c]\n",
    "                    finite = this[np.isfinite(this)]\n",
    "                    fill = np.repeat(finite, np.ceil(len(this)/len(finite)))[:len(this)]\n",
    "                    x[:,c] = np.where(np.isfinite(this), this, fill)\n",
    "            \n",
    "            # Construct new array\n",
    "            X1.append(x)\n",
    "        X1, nanmean = np.array(X1), np.array(nanmean)\n",
    "        \n",
    "        ## 2nd round\n",
    "        candidate_mean = []\n",
    "        for i in range(nanmean.shape[1]):\n",
    "            col = nanmean[i]\n",
    "            finite = col[np.isfinite(col)]\n",
    "            candidate_mean.append(finite)\n",
    "\n",
    "        X2 = []\n",
    "        for i in range(X1.shape[0]):\n",
    "            x = X[i]\n",
    "            indice = ~np.isfinite(x)\n",
    "            # Columns with full Nan\n",
    "            col_is_nan = np.all(indice, axis=0)\n",
    "            if (col_is_nan == True).any():\n",
    "                col = np.where(col_is_nan == True)[0]\n",
    "                for c in col:\n",
    "                    value = np.random.choice(candidate_mean[c])\n",
    "                    x = np.nan_to_num(x, nan=value)\n",
    "            X2.append(x)\n",
    "        \n",
    "        X = np.array(X2)\n",
    "\n",
    "        ## Final\n",
    "        X = X.reshape(X.shape[0], -1) # Flatten\n",
    "        print(\"Expected True:\", np.all(np.isfinite(X))) # expected True\n",
    "        return X\n",
    "\n",
    "\n",
    "fe = FeatureExtractor()\n",
    "# X_target = fe.transform(X_train.target)\n",
    "# np.all(np.isfinite(X_target)) # expected True\n",
    "[X_source, X_source_bkg, X_target, X_target_unlabeled, X_target_bkg,\n",
    "    y_source, y_target, X_test] = rename_dataset(\n",
    "    fe, X_train, y_train, X_test, y_test, show_imbalance=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(438, 6048)\n"
     ]
    }
   ],
   "source": [
    "print(X_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier detection\n",
    "\n",
    "Requirement:\n",
    "- input array must be 2D, i.e. (n_samples, n_features)\n",
    "- input array must not contain NaN, Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LocalOutlierFactor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-247be0d8f3a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# LocalOutlierFactor: 204s X_source_bkg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalOutlierFactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontamination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnovelty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LocalOutlierFactor' is not defined"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "X = deepcopy(X_source_bkg)\n",
    "np.nan_to_num(X, copy=False)\n",
    "# LocalOutlierFactor: 204s X_source_bkg\n",
    "lof = LocalOutlierFactor(contamination=0.01, novelty=False)\n",
    "flag = lof.fit_predict(X)\n",
    "print(flag.shape)\n",
    "X[flag==True].shape\n",
    "# IsolationForest: 296s\n",
    "from sklearn.ensemble import IsolationForest\n",
    "IF = IsolationForest(contamination=0.01)\n",
    "flag = IF.fit_predict(X)\n",
    "print(flag.shape)\n",
    "X[flag==True].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整理数据（Normalization, Oversampling, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop\n",
    "X_source = X_source.reshape(X_source.shape[0], -1)\n",
    "X_source_bkg = X_source_bkg.reshape(X_source_bkg.shape[0], -1)\n",
    "X_target = X_target.reshape(X_target.shape[0], -1)\n",
    "X_target_unlabeled = X_target_unlabeled.reshape(X_target_unlabeled.shape[0], -1)\n",
    "X_target_bkg = X_target_bkg.reshape(X_target_bkg.shape[0], -1)\n",
    "X_test.target = X_test.target.reshape(X_test.target.shape[0], -1)\n",
    "np.all(np.isfinite(X_source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_DT = DecisionTreeClassifier(max_depth=2, random_state=44,)\n",
    "\n",
    "model_RF = RandomForestClassifier(\n",
    "    n_estimators=2, max_depth=2, random_state=44, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_DT.fit(X_source, y_source)\n",
    "model_RF.fit(X_source, y_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(\"X_test.target.shape:\", X_test.target.shape)\n",
    "\n",
    "print(\"[train: B] Random Forest:\", model_RF.score(X_target, y_target))\n",
    "print(\"[test:  B] Random Forest:\", model_RF.score(X_test.target, y_test.target))\n",
    "y_pred = model_RF.predict(X_test.target)\n",
    "print(\"Predicted:\", Counter(y_pred), y_pred.shape)\n",
    "print(\"True:      \", Counter(y_test.target), y_test.target.shape)\n",
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查bug\n",
    "直接使用华为提供的比赛工具包来评价模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "Test data\n",
      "-------------------------------------\n",
      "training ap on fold 0 = 0.350\n",
      "validation ap on fold 0 = 0.287\n",
      "test ap on fold 0 = 0.167\n",
      "-------------------------------------\n",
      "training ap on fold 1 = 0.389\n",
      "validation ap on fold 1 = 0.276\n",
      "test ap on fold 1 = 0.167\n",
      "-------------------------------------\n",
      "training ap on fold 2 = 0.186\n",
      "validation ap on fold 2 = 0.293\n",
      "test ap on fold 2 = 0.189\n",
      "-------------------------------------\n",
      "training ap on fold 3 = 0.533\n",
      "validation ap on fold 3 = 0.281\n",
      "test ap on fold 3 = 0.171\n",
      "-------------------------------------\n",
      "training ap on fold 4 = 0.287\n",
      "validation ap on fold 4 = 0.296\n",
      "test ap on fold 4 = 0.166\n",
      "-------------------------------------\n",
      "training ap on fold 5 = 0.275\n",
      "validation ap on fold 5 = 0.311\n",
      "test ap on fold 5 = 0.172\n",
      "-------------------------------------\n",
      "training ap on fold 6 = 0.213\n",
      "validation ap on fold 6 = 0.318\n",
      "test ap on fold 6 = 0.187\n",
      "-------------------------------------\n",
      "training ap on fold 7 = 0.233\n",
      "validation ap on fold 7 = 0.299\n",
      "test ap on fold 7 = 0.165\n",
      "-------------------------------------\n",
      "training ap on fold 8 = 0.550\n",
      "validation ap on fold 8 = 0.307\n",
      "test ap on fold 8 = 0.188\n",
      "-------------------------------------\n",
      "training ap on fold 9 = 0.296\n",
      "validation ap on fold 9 = 0.299\n",
      "test ap on fold 9 = 0.183\n"
     ]
    }
   ],
   "source": [
    "import rampwf as rw\n",
    "import numpy as np\n",
    "from others import cd\n",
    "\n",
    "ap_bagged_test = []\n",
    "\n",
    "\n",
    "# 载入数据\n",
    "with cd(\"~/Codes/HuaweiRAMP\"):\n",
    "    problem = rw.utils.assert_read_problem()\n",
    "    X_train, y_train = problem.get_train_data(show=False)\n",
    "    X_test, y_test = problem.get_test_data(show=False)\n",
    "# 导入评价函数\n",
    "ap    = problem.score_types[0]\n",
    "# 设置crossvalidation\n",
    "splits = problem.get_cv(X_train, y_train, n_splits=10) # 默认10\n",
    "# 开始实验\n",
    "ap_train, ap_valid, ap_test, = [], [], []\n",
    "y_test_preds = []\n",
    "for fold_i, (train_is, valid_is) in enumerate(splits):\n",
    "    trained_workflow = problem.workflow.train_submission(\n",
    "        '.', X_train, y_train, train_is,)\n",
    "    X_fold_train = X_train.slice(train_is)\n",
    "    X_fold_valid = X_train.slice(valid_is)\n",
    "    \n",
    "    y_train_pred = problem.workflow.test_submission(trained_workflow, X_fold_train)\n",
    "    y_valid_pred = problem.workflow.test_submission(trained_workflow, X_fold_valid)\n",
    "    y_test_pred = problem.workflow.test_submission(trained_workflow, X_test)\n",
    "    ap_train.append( ap(y_train.slice(train_is).target, y_train_pred[:,1]) )\n",
    "    ap_valid.append( ap(y_train.slice(valid_is).target, y_valid_pred[:,1]) )\n",
    "    ap_test.append( ap(y_test.target, y_test_pred[:,1]) )\n",
    "    print('-------------------------------------')\n",
    "    print('training ap on fold {} = {:.3f}'.format(fold_i, ap_train[-1]))\n",
    "    print('validation ap on fold {} = {:.3f}'.format(fold_i, ap_valid[-1]))\n",
    "    print('test ap on fold {} = {:.3f}'.format(fold_i, ap_test[-1]))\n",
    "    \n",
    "    y_test_preds.append(y_test_pred)\n",
    "\n",
    "# 计算排名指标: bagged average precision on test dataset\n",
    "score = ap(y_test.target, np.array([y_test_pred for y_test_pred in y_test_preds]).mean(axis=0)[:,1])\n",
    "ap_bagged_test.append(score)\n",
    "del problem, X_train, y_train, X_test, y_test, ap, splits, y_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_bagged_test[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots()\n",
    "fig.add_trace(go.Scatter(x=hp_range, y=ap_bagged_test, mode=\"lines\",\n",
    "                         name=\"sampling_strategy\"))\n",
    "fig.update_layout(xaxis_title=\"Hyperparameter\", yaxis_title=\"Bagged ap\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "77a176e6d68c62f570691917117cf1b3298ba06ea1b936eeef71e844f28195b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('huawei': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}